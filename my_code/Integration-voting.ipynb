{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 下载 NLTK 停用词库\n",
    "nltk.download('stopwords')  # 确保停用词库已下载\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# 加载 IMDB 数据集\n",
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.imdb.load_data(num_words=10000)\n",
    "\n",
    "# 创建一个反向映射词典\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "# 反向映射字典\n",
    "index_word = {index: word for word, index in word_index.items()}\n",
    "\n",
    "# 将电影评论的数字转为单词\n",
    "train_texts = [' '.join([index_word.get(i - 3, '?') for i in review]) for review in train_data]\n",
    "test_texts = [' '.join([index_word.get(i - 3, '?') for i in review]) for review in test_data]\n",
    "\n",
    "# 合并训练和测试数据\n",
    "texts = train_texts + test_texts\n",
    "labels = list(train_labels) + list(test_labels)\n",
    "\n",
    "# 将数据转换为 DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'category': labels  # 电影评论的标签：0（负面评论）和 1（正面评论）\n",
    "})\n",
    "\n",
    "# 显示前几行数据\n",
    "print(df.head())\n",
    "### 2.数据清理\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_word_vectors(file_path):\n",
    "    word_vectors = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = np.array([float(i) for i in parts[1:]], dtype=np.float32)\n",
    "            word_vectors[word] = vector\n",
    "    return word_vectors\n",
    "\n",
    "\n",
    "# 假设训练好的词向量存储在 word2vec.txt 文件中\n",
    "word_vectors = load_word_vectors('txt/word2vec_vectors_50d.txt')\n",
    "\n",
    "\n",
    "# 定义文本清理函数\n",
    "def clean_text(text):\n",
    "    # 转小写\n",
    "    text = text.lower()\n",
    "\n",
    "    # 去除标点符号和非字母字符（可选保留数字）\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "\n",
    "    # 按空格分词\n",
    "    words = text.split()\n",
    "\n",
    "    # 去除停用词\n",
    "    cleaned_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # 重新组合为字符串\n",
    "    cleaned_text = ' '.join(cleaned_words)\n",
    "\n",
    "    # 去除多余的空格\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# 清理所有文本数据\n",
    "texts = df['text'].apply(clean_text)\n",
    "df['cleaned_text'] = texts\n",
    "\n",
    "# 显示前几行数据查看清理结果\n",
    "print(df.head())\n",
    "### 3.转为词向量\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "texts = df['cleaned_text']\n",
    "\n",
    "# 文本分类的标签\n",
    "labels = df['category'].values  # 这是数字标签，0 - 1（正负面评论）\n",
    "\n",
    "# Text-CNN 参数\n",
    "embedding_size = 50  # 词向量维度\n",
    "sequence_length = 100  # 句子的最大长度\n",
    "num_classes = 2  # 正负面评论分类\n",
    "filter_sizes = [3, 4, 5]\n",
    "num_filters = 200  # 卷积核数量\n",
    "\n",
    "# 创建输入词向量\n",
    "inputs = []\n",
    "for sen in texts:\n",
    "    sentence_vector = []\n",
    "    for word in sen.split():\n",
    "        # 使用读取的词向量字典来获取每个单词的词向量\n",
    "        if word in word_vectors:\n",
    "            sentence_vector.append(word_vectors[word])  # 获取词向量\n",
    "        else:\n",
    "            sentence_vector.append(np.zeros(embedding_size))  # 如果词不在词汇表中，使用零向量\n",
    "    if len(sentence_vector) < sequence_length:\n",
    "        sentence_vector.extend([np.zeros(embedding_size)] * (sequence_length - len(sentence_vector)))\n",
    "    else:\n",
    "        sentence_vector = sentence_vector[:sequence_length]\n",
    "    inputs.append(np.array(sentence_vector))\n",
    "\n",
    "# 将 inputs 列表转换为一个 numpy 数组\n",
    "inputs_array = np.array(inputs)\n",
    "\n",
    "# 然后再转换为 PyTorch 张量\n",
    "inputs_tensor = torch.FloatTensor(inputs_array)\n",
    "\n",
    "# 标签转换为 PyTorch 张量\n",
    "labels_tensor = torch.LongTensor(labels)\n",
    "\n",
    "# 显示输入的形状\n",
    "print(inputs_tensor.shape)  # (batch_size, sequence_length, embedding_size)\n",
    "print(labels_tensor.shape)  # (batch_size,)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "dfe02f1317e57314"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "bbd1f5616ca6b4c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f024b88b98921d1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import ensemble\n",
    "from model import net\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs_tensor, labels_tensor, test_size=0.2, random_state=0)\n",
    "\n",
    "model1 = net.TextCNN()\n",
    "model2 = net.TransformerModel()\n",
    "model1.load_state_dict(torch.load(\"./model/txtcnn_model.pth\"))\n",
    "model2.load_state_dict(torch.load(\"./model/transformer_model.pth\"))\n",
    "\n",
    "# 加载调优过的模型和Tokenizer\n",
    "model3 = BertForSequenceClassification.from_pretrained(\"finetuned_bert_model\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"finetuned_bert_model\")\n",
    "\n",
    "\n",
    "# 使用多数投票集成组合模型\n",
    "avg = VotingClassifier(estimators=[( 'lr' , model1), ( 'dt' , model2) , ( 'svc' , model3)], Voting= 'hard' ) \n",
    " \n",
    "# 在训练数据上拟合集成 ensemble.fit\n",
    "avg.fit(X_train, y_train) \n",
    " \n",
    "# 在测试数据上评估集成的性能\n",
    "print ( f\"整体精准度：{ensemble.score(X_test, y_test)* 100 } %\" )\n"
   ],
   "id": "df443ed1abf0349a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
